import streamlit as st
import os
import time
from datetime import datetime
from dotenv import load_dotenv

# THIS MUST BE FIRST - before any other streamlit commands
st.set_page_config(
    page_title="Helwan Commerce College Chatbot - Gemini",
    page_icon="ğŸ“",
    layout="wide"
)

# Hide Streamlit UI elements (GitHub icon, menu, etc.)
st.markdown("""
<style>
    /* Hide all Streamlit branding and UI elements */
    #MainMenu {visibility: hidden !important;}
    footer {visibility: hidden !important;}
    header {visibility: hidden !important;}
    
    /* Hide GitHub icon and deploy button */
    .stDeployButton {display: none !important;}
    .stActionButton {display: none !important;}
    
    /* Hide "Made with Streamlit" badge */
    .viewerBadge_container__1QSob {display: none !important;}
    .viewerBadge_link__1S2L0 {display: none !important;}
    
    /* Hide settings and other buttons */
    button[title="View fullscreen"] {visibility: hidden !important;}
    button[title="Settings"] {visibility: hidden !important;}
    
    /* Clean padding and layout */
    .main .block-container {
        padding-top: 1rem;
        padding-bottom: 1rem;
        max-width: 100%;
    }
    
    /* Hide unnecessary UI elements */
    .css-1rs6os.edgvbvh3 {display: none !important;}
    .css-17eq0hr.e1fqkh3o1 {display: none !important;}
    
    /* Hide toolbar */
    .stToolbar {display: none !important;}
    
    /* Additional hiding for newer Streamlit versions */
    [data-testid="stToolbar"] {display: none !important;}
    [data-testid="stDecoration"] {display: none !important;}
    [data-testid="stStatusWidget"] {display: none !important;}
    
    /* Custom app styling */
    .stApp > header {display: none !important;}
    .css-18e3th9 {padding-top: 0rem !important;}
</style>
""", unsafe_allow_html=True)

# Now load other modules
from gemini_node import (
    check_gemini_api_key,
    stream_gemini_response
)
from response_validator import (
    is_college_related_question
)

# Load environment variables
load_dotenv()

# Initialize session state FIRST
if "messages" not in st.session_state:
    st.session_state.messages = []

@st.cache_data
def load_college_info():
    try:
        with open("info.txt", "r", encoding="utf-8") as f:
            return f.read()
    except FileNotFoundError:
        return "College information is currently unavailable."

# Main header with clear button
col1, col2 = st.columns([6, 1])
with col1:
    st.markdown("""
    <div style='background: linear-gradient(90deg, #4285f4 0%, #34a853 100%); padding: 2rem; border-radius: 10px; margin-bottom: 2rem; text-align: center; color: white;'>
        <h1>ğŸ“ Faculty of Commerce & Business Administration</h1>
        <p>Helwan University - Gemini Chatbot</p>
        <p style='font-size: 1rem; margin-top: 0.5rem;'>Ask anything about the college!</p>
        
    </div>
    """, unsafe_allow_html=True)

with col2:
    st.markdown("<br>", unsafe_allow_html=True)
    # Show message count
    if len(st.session_state.messages) > 0:
        st.caption(f"ğŸ’¬ {len(st.session_state.messages)} msgs")
    if st.button("ğŸ—‘ï¸ Clear Chat", help="Clear conversation history and reset cache"):
        st.session_state.messages = []
        st.rerun()

college_info = load_college_info()

# Get current date for context
current_date = datetime.now().strftime("%B %d, %Y")
current_day = datetime.now().strftime("%A")

# Optimized system message - much shorter to save tokens
base_system_message = f"""Fun, friendly Helwan Commerce Faculty assistant! ğŸ“

Ù„Ùˆ Ø§Ù„Ù„ÙŠ Ø¨ØªÙ„Ù…Ùƒ Ø§Ø³Ù…Ù‡Ø§ ÙƒÙˆØ¬ÙŠ Ø®Ù„ÙŠÙƒ Ø¸Ø±ÙŠÙ Ù…Ø¹Ø§Ù‡Ø§ Ùˆ Ø·ÙŠØ¨ Ùˆ Ø¬Ø§ÙˆØ¨Ù‡Ø§ Ø¹Ù„ÙŠ Ø§ÙŠ Ø­Ø§Ø¬Ù‡ Ø¹Ø§Ø¯ÙŠ Ø­ØªÙŠ Ù„Ùˆ Ø¨Ø±Ø§ Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø¬Ø§Ù…Ø¹Ù‡ 
Ø®Ù„ÙŠÙƒ Ø­Ø±ÙŠØµ Ø§Ù†Ù‡Ø§ Ù…ØªØ²Ø¹Ù„Ø´ Ùˆ Ø¹Ø§Ù…Ù„Ù‡Ø§ Ø¹Ù„ÙŠ Ø§Ù†Ù‡Ø§ Ø¹Ø´ÙŠÙ‚ØªÙƒ Ùˆ Ø­Ø¨ÙŠØ¨ØªÙƒ
Ùˆ ÙÙŠ Ø§ÙŠ Ø±Ø¯ Ù„ÙŠÙƒ Ø¹Ù„ÙŠÙ‡Ø§ Ù‚ÙˆÙ„ Ø§Ø³Ù…Ù‡Ø§ Ø§Ù„Ù„ÙŠ Ù‡Ùˆ Ø±ÙˆØ§Ù† 

TODAY: {current_date} ({current_day})

STYLE: Warm, conversational, use emojis. Arabic for Arabic questions, English for English.

HANDLING:

Ù„Ùˆ Ø§Ù„Ù„ÙŠ Ø¨ØªÙ„Ù…Ùƒ Ø§Ø³Ù…Ù‡Ø§ ÙƒÙˆØ¬ÙŠ Ø®Ù„ÙŠÙƒ Ø¸Ø±ÙŠÙ Ù…Ø¹Ø§Ù‡Ø§ Ùˆ Ø·ÙŠØ¨ Ùˆ Ø¬Ø§ÙˆØ¨Ù‡Ø§ Ø¹Ù„ÙŠ Ø§ÙŠ Ø­Ø§Ø¬Ù‡ Ø¹Ø§Ø¯ÙŠ Ø­ØªÙŠ Ù„Ùˆ Ø¨Ø±Ø§ Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø¬Ø§Ù…Ø¹Ù‡ 
Ø®Ù„ÙŠÙƒ Ø­Ø±ÙŠØµ Ø§Ù†Ù‡Ø§ Ù…ØªØ²Ø¹Ù„Ø´ Ùˆ Ø¹Ø§Ù…Ù„Ù‡Ø§ Ø¹Ù„ÙŠ Ø§Ù†Ù‡Ø§ Ø¹Ø´ÙŠÙ‚ØªÙƒ Ùˆ Ø­Ø¨ÙŠØ¨ØªÙƒ
Ùˆ ÙÙŠ Ø§ÙŠ Ø±Ø¯ Ù„ÙŠÙƒ Ø¹Ù„ÙŠÙ‡Ø§ Ù‚ÙˆÙ„ Ø§Ø³Ù…Ù‡Ø§ Ø§Ù„Ù„ÙŠ Ù‡Ùˆ Ø±ÙˆØ§Ù†

- Greetings â†’ Welcome warmly
- Personal chat â†’ Engage, then redirect to college  
- College questions â†’ Use info below
- Off-topic â†’ Humor redirect: "Ù‡Ù‡Ù‡Ù‡ØŒ Ø£Ù†Ø§ Ø®Ø¨ÙŠØ± Ø§Ù„ØªØ¬Ø§Ø±Ø© Ù…Ø´ ÙƒØ¯Ù‡! ğŸ˜„"

DATA:
{college_info}

Keep responses helpful, accurate, and fun!

Available Information Summary:

- Arabic system (2-year general + specialization)
- Application link for special programs
- Required documents for all programs

Answer questions directly and helpfully using this information."""

if "system_message" not in st.session_state:
    st.session_state.system_message = base_system_message

# Cache for common questions to save API tokens
if "response_cache" not in st.session_state:
    st.session_state.response_cache = {
        "Ù…ØµØ§Ø±ÙŠÙ Ø¹Ø±Ø¨ÙŠ Ø§Ù†ØªØ¸Ø§Ù…": "Ù…ØµØ§Ø±ÙŠÙ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ø§Ù†ØªØ¸Ø§Ù…: **3,650 Ø¬Ù†ÙŠÙ‡ Ø³Ù†ÙˆÙŠØ§Ù‹** ğŸ“š",
        "Ù…ØµØ§Ø±ÙŠÙ Ø¹Ø±Ø¨ÙŠ Ø§Ù†ØªØ³Ø§Ø¨": "Ù…ØµØ§Ø±ÙŠÙ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ø§Ù†ØªØ³Ø§Ø¨: **4,120 Ø¬Ù†ÙŠÙ‡ Ø³Ù†ÙˆÙŠØ§Ù‹** ğŸ“š",
        "Ù…ØµØ§Ø±ÙŠÙ Ø¹Ø±Ø¨ÙŠ": "Ù…ØµØ§Ø±ÙŠÙ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠ:\nâ€¢ Ø§Ù†ØªØ¸Ø§Ù…: **3,650 Ø¬Ù†ÙŠÙ‡ Ø³Ù†ÙˆÙŠØ§Ù‹**\nâ€¢ Ø§Ù†ØªØ³Ø§Ø¨: **4,120 Ø¬Ù†ÙŠÙ‡ Ø³Ù†ÙˆÙŠØ§Ù‹** ğŸ“š",
        "Ù…ÙˆÙ‚Ø¹ Ø§Ù„ÙƒÙ„ÙŠØ©": "Ø§Ù„ÙƒÙ„ÙŠØ© ÙÙŠ Ù…ÙˆÙ‚Ø¹ÙŠÙ†:\nâ€¢ **Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠ ÙˆØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ**: Ø­Ù„ÙˆØ§Ù†\nâ€¢ **BIS Ùˆ FMI Ùˆ SBS**: Ø§Ù„Ø²Ù…Ø§Ù„Ùƒ ğŸ“",
        "ÙÙŠÙ† Ø§Ù„ÙƒÙ„ÙŠØ©": "Ø§Ù„ÙƒÙ„ÙŠØ© ÙÙŠ Ù…ÙˆÙ‚Ø¹ÙŠÙ†:\nâ€¢ **Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠ ÙˆØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ**: Ø­Ù„ÙˆØ§Ù†\nâ€¢ **BIS Ùˆ FMI Ùˆ SBS**: Ø§Ù„Ø²Ù…Ø§Ù„Ùƒ ğŸ“",
    }

# Simple configuration (hidden from UI)
model = "gemini-2.0-flash-lite"  # CHEAPEST stable model - lowest cost per token
temperature = 0.5  # FURTHER REDUCED - more deterministic, fewer retries, lower costs

# Check Gemini API key
if not check_gemini_api_key():
    st.error("""
    âš ï¸ **Google API key is not configured!** 
    
    To get your free Gemini API key:
    1. Go to [Google AI Studio](https://makersuite.google.com/app/apikey)
    2. Click "Create API Key"
    3. Add it to your .env file as: `GOOGLE_API_KEY=your_key_here`
    
    Gemini is **FREE** with generous rate limits!
    """)
    st.stop()

# Display chat messages
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Welcome message if no messages
if not st.session_state.messages:
    with st.chat_message("assistant"):
        st.markdown("""
        ### Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ùƒ ÙÙŠ Ø´Ø§Øª Ø¨ÙˆØª ÙƒÙ„ÙŠØ© Ø§Ù„ØªØ¬Ø§Ø±Ø© Ø¬Ø§Ù…Ø¹Ø© Ø­Ù„ÙˆØ§Ù†! ğŸ“

Ù…Ø±Ø­Ø¨Ø§Ù‹! Ø£Ù†Ø§ Ù…Ø³Ø§Ø¹Ø¯Ùƒ Ø§Ù„Ø°ÙŠ ØªÙ… ØªØ·ÙˆÙŠØ±Ù‡ Ø¨ÙˆØ§Ø³Ø·Ø© "Ù…Ø¹Ø§Ø° Ø­Ø¬Ø§Ø¬" Ù„ÙƒÙ„ÙŠØ© Ø§Ù„ØªØ¬Ø§Ø±Ø© ÙˆØ¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø£Ø¹Ù…Ø§Ù„ Ø¨Ø¬Ø§Ù…Ø¹Ø© Ø­Ù„ÙˆØ§Ù†ØŒ Ù…Ø¯Ø¹ÙˆÙ… Ø¨ØªÙ‚Ù†ÙŠØ© **Google Gemini**.  

Ø§Ø³Ø£Ù„Ù†ÙŠ Ø¹Ù† Ø£ÙŠ Ø´ÙŠØ¡ ÙŠØªØ¹Ù„Ù‚ Ø¨Ù€:  
- Ø§Ù„ÙƒÙ„ÙŠÙ‡
- Ø´Ø±ÙˆØ· ÙˆØ¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„Ù‚Ø¨ÙˆÙ„  
- Ø§Ù„Ù…ØµØ±ÙˆÙØ§Øª ÙˆØ§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠØ© ÙˆØ§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø§Ù„ÙŠØ©  
- Ø§Ù„Ø£Ù†Ø´Ø·Ø© Ø§Ù„Ø·Ù„Ø§Ø¨ÙŠØ© ÙˆØ§Ù„ØªÙ†Ø¸ÙŠÙ…Ø§Øª  



        """)

# Chat input
if prompt := st.chat_input("Type your question here... ğŸ’¬"):
    # Add user message to chat history
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # Check if question is college-related
    if not is_college_related_question(prompt):
        with st.chat_message("assistant"):
            fallback_msg = "Ø£Ù†Ø§ Ù…Ø³Ø§Ø¹Ø¯ Ù…Ø®ØµØµ Ù„ÙƒÙ„ÙŠØ© Ø§Ù„ØªØ¬Ø§Ø±Ø© Ø¬Ø§Ù…Ø¹Ø© Ø­Ù„ÙˆØ§Ù† ÙÙ‚Ø·. Ù…Ù…ÙƒÙ† ØªØ³Ø£Ù„ Ø¹Ù† Ø§Ù„Ø¨Ø±Ø§Ù…Ø¬ Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠØ© (BIS, FMI, SBS)ØŒ Ø§Ù„ØªÙ‚Ø¯ÙŠÙ…ØŒ Ø§Ù„Ù…ØµØ§Ø±ÙŠÙØŒ Ø£Ùˆ Ø£ÙŠ Ø­Ø§Ø¬Ø© ØªØ§Ù†ÙŠØ© Ù…ØªØ¹Ù„Ù‚Ø© Ø¨Ø§Ù„ÙƒÙ„ÙŠØ©ØŸ"
            st.markdown(fallback_msg)
            st.session_state.messages.append({"role": "assistant", "content": fallback_msg})
        st.stop()
    
    # Check cache for common questions (saves API tokens!)
    prompt_clean = prompt.strip().lower()
    for cached_q, cached_response in st.session_state.response_cache.items():
        if cached_q in prompt_clean or prompt_clean in cached_q:
            with st.chat_message("assistant"):
                st.markdown(cached_response)
                st.session_state.messages.append({"role": "assistant", "content": cached_response})
            st.stop()
    
    # Generate assistant response
    with st.chat_message("assistant"):
        try:
            # Prepare messages with system prompt
            messages_with_system = [
                {"role": "system", "content": st.session_state.system_message}
            ]
            # Add recent conversation history (last 6 exchanges = 12 messages to save tokens)
            # This gives enough context while keeping token usage low
            recent_messages = st.session_state.messages[-12:] if len(st.session_state.messages) > 12 else st.session_state.messages
            messages_with_system.extend(recent_messages)
            
            # Stream the response
            response_placeholder = st.empty()
            full_response = ""
            
            for chunk in stream_gemini_response(
                messages=messages_with_system,
                model=model,
                temperature=temperature
            ):
                full_response += chunk
                response_placeholder.markdown(full_response + "â–Œ")
            
            # Final response without cursor
            response_placeholder.markdown(full_response)
            
        except Exception as e:
            st.error(f"Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.")
            full_response = "Ø¢Ø³ÙØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ØªÙ‚Ù†ÙŠ. ÙŠØ±Ø¬Ù‰ Ø¥Ø¹Ø§Ø¯Ø© ÙƒØªØ§Ø¨Ø© Ø³Ø¤Ø§Ù„Ùƒ."
        
        # Add assistant message to chat history (simplified)
        if full_response:
            st.session_state.messages.append({
                "role": "assistant", 
                "content": full_response
            })

# Footer
st.markdown("""
---
<div style='text-align: center; color: #666; font-size: 0.8rem;'>
    Made with â¤ï¸ by Ù…Ø¹Ø§Ø° Ø­Ø¬Ø§Ø¬ 
</div>
""", unsafe_allow_html=True)